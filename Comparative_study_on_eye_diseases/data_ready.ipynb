{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np \n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './'\n",
    "data_dir = pathlib.Path(\"./dataset/train/train\")\n",
    "\n",
    "classes_dic = {\n",
    "    \"CNV\" : list(data_dir.glob('CNV/*')),\n",
    "    \"DME\" : list(data_dir.glob('DME/*')),\n",
    "    \"DRUSEN\" : list(data_dir.glob('DRUSEN/*')),\n",
    "    \"NORMAL\" : list(data_dir.glob('NORMAL/*')),\n",
    "}\n",
    "classes_labels = {\n",
    "    \"CNV\" : 0,\n",
    "    \"DME\" : 1,\n",
    "    \"DRUSEN\" : 2,\n",
    "    \"NORMAL\" : 3,\n",
    "}\n",
    "\n",
    "test_dir = pathlib.Path(\"./dataset/validation/validation\")\n",
    "\n",
    "test_dic = {\n",
    "    \"CNV\" : list(test_dir.glob('CNV/*')),\n",
    "    \"DME\" : list(test_dir.glob('DME/*')),\n",
    "    \"DRUSEN\" : list(test_dir.glob('DRUSEN/*')),\n",
    "    \"NORMAL\" : list(test_dir.glob('NORMAL/*')),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_resize(img, func):\n",
    "    processed = func(img)\n",
    "    resized = cv2.resize(processed, (224,224))\n",
    "\n",
    "    if len(resized.shape) == 2:\n",
    "        resized = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "\n",
    "\n",
    "def get_data(dic, func):\n",
    "    image_data, label = [], []\n",
    "    final_image = (224,224)\n",
    "\n",
    "    for disease, images in dic.items():\n",
    "        for image in images:\n",
    "            img = cv2.imread(str(image))\n",
    "            x, y, z = img.shape\n",
    "            if (x == 496 and y == 512 ) or (x == 512 and y == 512) :  # Check against width and height separately\n",
    "                final = process_and_resize(img,func)  # Pass image_size as a tuple\n",
    "                image_data.append(final)\n",
    "                label.append(classes_labels[disease])\n",
    "    image_data = np.array(image_data)\n",
    "    label = np.array(label)\n",
    "\n",
    "    return  image_data, label\n",
    "\n",
    "def balance_dataset(count,image_data, label):\n",
    "    classes, counts = np.unique(label, return_counts=True)\n",
    "    min_count = count/4\n",
    "\n",
    "    # Undersample over-represented classes\n",
    "    balanced_data = []\n",
    "    for class_ in classes:\n",
    "        class_indices = np.where(label == class_)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "        balanced_data.extend(image_data[class_indices[:int(min_count)]])\n",
    "\n",
    "    balanced_data = np.array(balanced_data)\n",
    "    balanced_label = np.repeat(classes, min_count)\n",
    "\n",
    "    classes, counts = np.unique(balanced_label, return_counts=True)\n",
    "\n",
    "    # Print class counts\n",
    "    for class_, count in zip(classes, counts):\n",
    "        print(f\"Class {class_}: {count} instances\")\n",
    "    return balanced_data, balanced_label\n",
    "\n",
    "\n",
    "def shuffle_data(image_data, labels):\n",
    "    indices = np.arange(len(image_data))\n",
    "    np.random.shuffle(indices)\n",
    "    image_data = image_data[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    return image_data, labels\n",
    "\n",
    "\n",
    "def save_pickle(folder,name , image_data, labels):\n",
    "    with open(os.path.join(save_path,f\"./{folder}/{name}.pickle\"), 'wb') as f: #'wb' - file will be opened in writing mode\n",
    "        pickle.dump( (image_data, labels), f) # f is opened pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "def hsv(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "def median(image):\n",
    "    return cv2.medianBlur(image, 3)\n",
    "\n",
    "def clahecc(image):\n",
    "    \n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # Check if the image is not already grayscale\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        grayscale_image = image\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    clahe_image = clahe.apply(grayscale_image)\n",
    "\n",
    "    # Contrast Correction (optional)\n",
    "    clahe_cc_image = np.clip(2.5 * clahe_image - 128, 0, 255).astype(np.uint8)\n",
    "    return clahe_cc_image\n",
    "\n",
    "def he(image):\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # Check if the image is not already grayscale\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        grayscale_image = image\n",
    "    return cv2.equalizeHist(grayscale_image)\n",
    "\n",
    "def threshold(image):\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # Check if the image is not already grayscale\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        grayscale_image = image\n",
    "    return cv2.adaptiveThreshold(grayscale_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 1)\n",
    "\n",
    "def gabor(image):\n",
    "    # Define parameters for Gabor filter\n",
    "    ksize = 3  # Kernel size\n",
    "    sigma = 10\n",
    "    # Standard deviation of the Gaussian envelope\n",
    "    theta = np.pi/4  # Orientation of the normal to the parallel stripes of the Gabor function\n",
    "    lambda_ = 4  # Wavelength of the sinusoidal factor\n",
    "    gamma = 0.25  # Spatial aspect ratio\n",
    "    phi = 1  # Phase offset of the sinusoidal factor\n",
    "\n",
    "    # Generate Gabor filter\n",
    "    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambda_, gamma, phi, ktype=cv2.CV_32F)\n",
    "\n",
    "    # Apply Gabor filter to the image\n",
    "    filtered_image = cv2.filter2D(image, cv2.CV_8UC3, kernel)\n",
    "    return filtered_image\n",
    "\n",
    "def canny(image):\n",
    "    # Convert image to grayscale\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:  # Check if the image is not already grayscale\n",
    "        grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        grayscale_image = image\n",
    "    \n",
    "    # Apply Gaussian blur to the grayscale image\n",
    "    blurred_image = cv2.GaussianBlur(grayscale_image, (5, 5), 0)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(blurred_image, 50, 150)  # You can adjust the threshold values here\n",
    "    \n",
    "    return edges\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. lab + hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first(image):\n",
    "    a = lab(image)\n",
    "    b = hsv(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. lab + clachecc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second(image):\n",
    "    a = lab(image)\n",
    "    c = clahecc(a)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third(image):\n",
    "    return he(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourth(image):\n",
    "    return threshold(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Gabor filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fifth(image):\n",
    "    a = hsv(image)\n",
    "    b = median(a)\n",
    "    return gabor(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sixth(image):\n",
    "    return canny(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 800 instances\n",
      "Class 1: 800 instances\n",
      "Class 2: 800 instances\n",
      "Class 3: 800 instances\n",
      "________________________________________________________\n",
      "Class 0: 250 instances\n",
      "Class 1: 250 instances\n",
      "Class 2: 250 instances\n",
      "Class 3: 250 instances\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "print(\"________________________________________________________\")\n",
    "train_data, train_labels = get_data(classes_dic, first)\n",
    "\n",
    "train_data, train_labels = balance_dataset(3200,train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = shuffle_data(train_data, train_labels)\n",
    "\n",
    "save_pickle(\"first\",\"train_first\", train_data, train_labels)\n",
    "print(\"________________________________________________________\")\n",
    "# testing data\n",
    "test_data, test_labels = get_data(test_dic, first)\n",
    "\n",
    "test_data, test_labels = balance_dataset(1000,test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = shuffle_data(test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = test_data[:1000], test_labels[:1000]\n",
    "\n",
    "save_pickle(\"first\",\"test_first\", test_data, test_labels)\n",
    "print(\"________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 800 instances\n",
      "Class 1: 800 instances\n",
      "Class 2: 800 instances\n",
      "Class 3: 800 instances\n",
      "________________________________________________________\n",
      "Class 0: 250 instances\n",
      "Class 1: 250 instances\n",
      "Class 2: 250 instances\n",
      "Class 3: 250 instances\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "print(\"________________________________________________________\")\n",
    "train_data, train_labels = get_data(classes_dic, second)\n",
    "\n",
    "train_data, train_labels = balance_dataset(3200,train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = shuffle_data(train_data, train_labels)\n",
    "\n",
    "save_pickle(\"second\",\"train_second\", train_data, train_labels)\n",
    "\n",
    "# testing data\n",
    "print(\"________________________________________________________\")\n",
    "test_data, test_labels = get_data(test_dic, second)\n",
    "\n",
    "test_data, test_labels = balance_dataset(1000,test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = shuffle_data(test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = test_data[:1000], test_labels[:1000]\n",
    "\n",
    "save_pickle(\"second\",\"test_second\", test_data, test_labels)\n",
    "print(\"________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Class 0: 800 instances\n",
      "Class 1: 800 instances\n",
      "Class 2: 800 instances\n",
      "Class 3: 800 instances\n",
      "________________________________________________________\n",
      "Class 0: 250 instances\n",
      "Class 1: 250 instances\n",
      "Class 2: 250 instances\n",
      "Class 3: 250 instances\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"________________________________________________________\")\n",
    "# training data\n",
    "train_data, train_labels = get_data(classes_dic, third)\n",
    "\n",
    "train_data, train_labels = balance_dataset(3200,train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = shuffle_data(train_data, train_labels)\n",
    "\n",
    "save_pickle(\"third\",\"train_third\", train_data, train_labels)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "# testing data\n",
    "test_data, test_labels = get_data(test_dic, third)\n",
    "\n",
    "test_data, test_labels = balance_dataset(1000,test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = shuffle_data(test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = test_data[:1000], test_labels[:1000]\n",
    "\n",
    "save_pickle(\"third\",\"test_third\", test_data, test_labels)\n",
    "print(\"________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "Class 0: 800 instances\n",
      "Class 1: 800 instances\n",
      "Class 2: 800 instances\n",
      "Class 3: 800 instances\n",
      "________________________________________________________\n",
      "Class 0: 250 instances\n",
      "Class 1: 250 instances\n",
      "Class 2: 250 instances\n",
      "Class 3: 250 instances\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "print(\"________________________________________________________\")\n",
    "train_data, train_labels = get_data(classes_dic, fourth)\n",
    "\n",
    "train_data, train_labels = balance_dataset(3200,train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = shuffle_data(train_data, train_labels)\n",
    "\n",
    "save_pickle(\"fourth\",\"train_fourth\", train_data, train_labels)\n",
    "\n",
    "print(\"________________________________________________________\")\n",
    "# testing data\n",
    "test_data, test_labels = get_data(test_dic, fourth)\n",
    "\n",
    "test_data, test_labels = balance_dataset(1000,test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = shuffle_data(test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = test_data[:1000], test_labels[:1000]\n",
    "\n",
    "save_pickle(\"fourth\",\"test_fourth\", test_data, test_labels)\n",
    "print(\"________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Fifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 800 instances\n",
      "Class 1: 800 instances\n",
      "Class 2: 800 instances\n",
      "Class 3: 800 instances\n",
      "________________________________________________________\n",
      "Class 0: 250 instances\n",
      "Class 1: 250 instances\n",
      "Class 2: 250 instances\n",
      "Class 3: 250 instances\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "print(\"________________________________________________________\")\n",
    "train_data, train_labels = get_data(classes_dic, fifth)\n",
    "\n",
    "train_data, train_labels = balance_dataset(3200,train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = shuffle_data(train_data, train_labels)\n",
    "\n",
    "save_pickle(\"fifth\",\"train_fifth\", train_data, train_labels)\n",
    "\n",
    "# testing data\n",
    "print(\"________________________________________________________\")\n",
    "test_data, test_labels = get_data(test_dic, fifth)\n",
    "\n",
    "test_data, test_labels = balance_dataset(1000,test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = shuffle_data(test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = test_data[:1000], test_labels[:1000]\n",
    "\n",
    "save_pickle(\"fifth\",\"test_fifth\", test_data, test_labels)\n",
    "print(\"________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Sixth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 800 instances\n",
      "Class 1: 800 instances\n",
      "Class 2: 800 instances\n",
      "Class 3: 800 instances\n",
      "________________________________________________________\n",
      "Class 0: 250 instances\n",
      "Class 1: 250 instances\n",
      "Class 2: 250 instances\n",
      "Class 3: 250 instances\n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "print(\"________________________________________________________\")\n",
    "train_data, train_labels = get_data(classes_dic, sixth)\n",
    "\n",
    "train_data, train_labels = balance_dataset(3200,train_data, train_labels)\n",
    "\n",
    "train_data, train_labels = shuffle_data(train_data, train_labels)\n",
    "\n",
    "save_pickle(\"sixth\",\"train_sixth\", train_data, train_labels)\n",
    "\n",
    "# testing data\n",
    "print(\"________________________________________________________\")\n",
    "test_data, test_labels = get_data(test_dic, sixth)\n",
    "\n",
    "test_data, test_labels = balance_dataset(1000,test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = shuffle_data(test_data, test_labels)\n",
    "\n",
    "test_data, test_labels = test_data[:1000], test_labels[:1000]\n",
    "\n",
    "save_pickle(\"sixth\",\"test_sixth\", test_data, test_labels)\n",
    "print(\"________________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
