{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './eeg-during-mental-arithmetic-tasks-1.0.0/'\n",
    "\n",
    "rest_filepaths = []\n",
    "task_filepaths = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if filename.endswith('.edf'):\n",
    "        label = filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "        if label == '1':\n",
    "            rest_filepaths.append(filepath)\n",
    "        else:\n",
    "            task_filepaths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    data = mne.io.read_raw_edf(filepath, preload=True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=0.5, h_freq=45)\n",
    "    tmin, tmax = 0, 61.99\n",
    "    data.crop(tmin=tmin, tmax=tmax)\n",
    "    \n",
    "\n",
    "    # if array.shape[0]>121:\n",
    "    #     array = resample(array, replace=False, n_samples=average_epochs, random_state=42)\n",
    "    # else:\n",
    "    #     # Oversample 'task' epochs to the average value\n",
    "    #     array = resample(array, replace=True, n_samples=average_epochs, random_state=42)\n",
    "    return data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rest_epochs_array = [read_data(filepath) for filepath in rest_filepaths]\n",
    "task_epochs_array = [read_data(filepath) for filepath in task_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 21, 30996)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_epochs_array = np.array(rest_epochs_array)\n",
    "task_epochs_array = np.array(task_epochs_array)\n",
    "rest_epochs_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels:\n",
    "rest_label = [0 for _ in rest_epochs_array]\n",
    "task_label = [1 for _ in task_epochs_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = np.concatenate((rest_epochs_array, task_epochs_array))\n",
    "all_labels = rest_label + task_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = np.random.permutation(72)\n",
    "\n",
    "# Shuffle both arrays using the same permutation along the first axis\n",
    "shuffled_epochs = []\n",
    "shuffled_labels = []\n",
    "\n",
    "for index in perm:\n",
    "    shuffled_epochs.append(all_epochs[index])\n",
    "    shuffled_labels.append(all_labels[index])\n",
    "\n",
    "all_epochs = shuffled_epochs\n",
    "all_labels = shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 21, 30996)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_epochs), len(all_epochs[0]), len(all_epochs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.array(all_epochs)\n",
    "label_array = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 21, 30996) (72,)\n"
     ]
    }
   ],
   "source": [
    "print(data_array.shape, label_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "import numpy as np\n",
    "eeg_data= data_array\n",
    "\n",
    "\n",
    "# Assuming your EEG data is stored in a variable called `eeg_data`\n",
    "# Shape of eeg_data: (72, 21, 30951)\n",
    "\n",
    "# Initialize an array to store the normalized data\n",
    "normalized_data = np.zeros_like(eeg_data)\n",
    "\n",
    "means = np.mean(eeg_data, axis=(0, 2))\n",
    "stds = np.std(eeg_data, axis=(0, 2))\n",
    "\n",
    "# Normalize each channel for all candidates\n",
    "for candidate in range(eeg_data.shape[0]):\n",
    "    for channel in range(eeg_data.shape[1]):\n",
    "        normalized_data[candidate, channel, :] = (eeg_data[candidate, channel, :] - means[channel]) / stds[channel]\n",
    "\n",
    "# normalized_eeg_data now contains the z-score normalized EEG data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_array_one_hot = to_categorical(label_array)\n",
    "label_array_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([72, 21, 30996, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_reshaped = tf.reshape(normalized_data, (-1, 21, 30996, 1))\n",
    "input_data_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (72, 21, 30996, 1)\n",
      "after conv2d   (72, 21, 861, 256)\n",
      "after batch   (72, 21, 861, 256)\n",
      "after depthwise conv2d   (72, 2, 861, 256)\n"
     ]
    }
   ],
   "source": [
    "# Define Conv2D layer\n",
    "input_shape = input_data_reshaped.shape\n",
    "print(\"input shape: \", input_shape)\n",
    "\n",
    "conv2d_layer = tf.keras.layers.Conv2D(filters=256, kernel_size=(1, 36), strides=(1, 36), padding='valid', input_shape=input_shape)\n",
    "\n",
    "# Define BatchNormalization layer\n",
    "batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "# Define DepthwiseConv2D layer\n",
    "depthwise_conv2d_layer = tf.keras.layers.DepthwiseConv2D(kernel_size=(8, 1), strides=(8,1),padding='valid')\n",
    "\n",
    "# Pass input_data through Conv2D layer\n",
    "x = conv2d_layer(input_data_reshaped)\n",
    "print(\"after conv2d  \", x.shape)\n",
    "\n",
    "# Pass output through BatchNormalization layer\n",
    "x = batch_norm_layer(x)\n",
    "print(\"after batch  \", x.shape)\n",
    "\n",
    "# Pass output through DepthwiseConv2D layer\n",
    "output = depthwise_conv2d_layer(x)\n",
    "print(\"after depthwise conv2d  \", output.shape)\n",
    "\n",
    "np.savez('image_patches.npz', data=output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run from here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Dense, Dropout, Embedding, GlobalAveragePooling1D, Input, Layer, LayerNormalization, MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT from scratch:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchEncoder(Layer):\n",
    "    def __init__(self, num_patches=256, projection_dim=1722):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim = projection_dim\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        class_token = w_init(shape=(1, projection_dim), dtype=\"float32\")\n",
    "        self.class_token = tf.Variable(initial_value=class_token, trainable=True)\n",
    "        self.projection = Dense(units=projection_dim)\n",
    "        self.position_embedding = Embedding(input_dim=num_patches+1, output_dim=projection_dim)\n",
    "        \n",
    "    def call(self, patch):\n",
    "        batch = tf.shape(patch)[0]\n",
    "        # reshape the class token embedins\n",
    "        class_token = tf.tile(self.class_token, multiples = [batch, 1])\n",
    "        class_token = tf.reshape(class_token, (batch, 1, self.projection_dim))\n",
    "        # calculate patches embeddings\n",
    "        patches_embed = self.projection(patch)\n",
    "        patches_embed = tf.concat([patches_embed, class_token], 1)\n",
    "        # calcualte positional embeddings\n",
    "        positions = tf.range(start=0, limit=self.num_patches+1, delta=1)\n",
    "        positions_embed = self.position_embedding(positions)\n",
    "        # add both embeddings\n",
    "        encoded = patches_embed + positions_embed\n",
    "        return encoded\n",
    "        \n",
    "        \n",
    "class MLP(Layer):\n",
    "    def __init__(self, hidden_features, out_features, dropout_rate=0.1, activation_func = None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dense1 = Dense(hidden_features, activation=tf.nn.gelu)\n",
    "        self.dense2 = Dense(out_features, activation=activation_func)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        y = self.dropout(x)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "class Block(Layer):\n",
    "    def __init__(self, projection_dim, num_heads=4, dropout_rate=0.1):\n",
    "        super(Block, self).__init__()\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=dropout_rate)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.mlp = MLP(projection_dim * 2, projection_dim, dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Layer normalization 1.\n",
    "        x1 = self.norm1(x) # encoded_patches\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = self.attn(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = Add()([attention_output, x]) #encoded_patches\n",
    "        # Layer normalization 2.\n",
    "        x3 = self.norm2(x2)\n",
    "        # MLP.\n",
    "        x3 = self.mlp(x3)\n",
    "        # Skip connection 2.\n",
    "        y = Add()([x3, x2])\n",
    "        return y\n",
    "    \n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, projection_dim, num_heads=4, num_blocks=12, dropout_rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.blocks = [Block(projection_dim, num_heads, dropout_rate) for _ in range(num_blocks)]\n",
    "        self.norm = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Create a [batch_size, projection_dim] tensor.\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        x = self.norm(x)\n",
    "        y = self.dropout(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 31739904 into shape (72,469,469)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(a, \u001b[38;5;241m861\u001b[39m)  \u001b[38;5;66;03m# Choose a maximum value that ensures reshaping works\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Reshape the array to (72, a, a)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m reshaped_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m72\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Print shapes for verification\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, original_array\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Atharva\\Anaconda3\\envs\\py_tf\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atharva\\Anaconda3\\envs\\py_tf\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 31739904 into shape (72,469,469)"
     ]
    }
   ],
   "source": [
    "# Example array with shape (72, 2, 861, 256)\n",
    "original_array = np.zeros((72, 2, 861, 256))\n",
    "\n",
    "# Calculate total number of elements\n",
    "total_elements = np.prod(original_array.shape)\n",
    "\n",
    "# Calculate a such that 72 * a * a = total_elements / 2\n",
    "a = int(np.sqrt(total_elements / (72 * 2)))\n",
    "\n",
    "# Adjust a to be a little smaller to avoid size mismatches\n",
    "a = min(a, 861)  # Choose a maximum value that ensures reshaping works\n",
    "\n",
    "# Reshape the array to (72, a, a)\n",
    "reshaped_array = np.reshape(original_array, (72, a, a))\n",
    "\n",
    "# Print shapes for verification\n",
    "print(\"Original Shape:\", original_array.shape)\n",
    "print(\"Reshaped Shape:\", reshaped_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_VisionTransformer(num_classes, num_patches=256, projection_dim=182, input_shape=(256, 182)):\n",
    "    patches = Input(shape=input_shape)\n",
    "    # Patch encoder\n",
    "    patches_embed = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "    # Transformer encoder\n",
    "    representation = TransformerEncoder(projection_dim)(patches_embed)\n",
    "    representation = GlobalAveragePooling1D()(representation)\n",
    "    # MLP to classify outputs\n",
    "    logits = MLP(projection_dim, num_classes, 0.5, 'sigmoid')(representation)\n",
    "    # Create model\n",
    "    model = Model(inputs=patches, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_VisionTransformer(2, input_shape=(256, 182))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "num_classes = 1  # For binary classification with sigmoid, num_classes should be 1\n",
    "\n",
    "\n",
    "\n",
    "gkf = GroupKFold(n_splits=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8784, 182, 256)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patches = np.moveaxis(patches, 1, 2)\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m11/42\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:50\u001b[0m 17s/step - accuracy: 0.4920 - loss: 7.3537"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "test_accuracy = []\n",
    "\n",
    "for train_index, test_index in gkf.split(patches, label_array, groups=group_array):\n",
    "    # Split data into train and test for this fold\n",
    "    train_features, test_features = patches[train_index], patches[test_index]\n",
    "    train_labels, test_labels = label_array[train_index], label_array[test_index]\n",
    "\n",
    "    train_features = np.moveaxis(train_features, 1, 2)\n",
    "    test_features = np.moveaxis(test_features, 1, 2)\n",
    "\n",
    "    train_features = np.reshape(train_features, (*train_features.shape, 1))\n",
    "    test_features = np.reshape(test_features, (*test_features.shape, 1))\n",
    "\n",
    "    # Initialize model\n",
    "\n",
    "    model = create_VisionTransformer(num_classes, input_shape=(256, 182))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model on current fold's train and validation data\n",
    "\n",
    "    model.fit(train_features, train_labels, epochs=10,\n",
    "              batch_size=128, validation_split=0.2)\n",
    "\n",
    "    # Evaluate model on test data for this fold\n",
    "    test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
    "    test_accuracy.append(test_acc)\n",
    "\n",
    "\n",
    "# After all folds, print average test accuracy\n",
    "\n",
    "\n",
    "print(\"Average Test Accuracy:\", np.mean(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 5s/step - accuracy: 0.4924 - loss: 8.0326 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 2/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m575s\u001b[0m 5s/step - accuracy: 0.5167 - loss: 7.7444 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 3/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 5s/step - accuracy: 0.5047 - loss: 7.9345 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 4/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 5s/step - accuracy: 0.5035 - loss: 7.9514 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 5/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 5s/step - accuracy: 0.5062 - loss: 7.9095 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 6/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 5s/step - accuracy: 0.5065 - loss: 7.9069 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 7/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 5s/step - accuracy: 0.5054 - loss: 7.9244 - val_accuracy: 0.7223 - val_loss: 1.5540\n",
      "Epoch 8/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 5s/step - accuracy: 0.4966 - loss: 8.0638 - val_accuracy: 0.7223 - val_loss: 2.4380\n",
      "Epoch 9/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 5s/step - accuracy: 0.5000 - loss: 8.0107 - val_accuracy: 0.7223 - val_loss: 2.5223\n",
      "Epoch 10/10\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 5s/step - accuracy: 0.4810 - loss: 8.3164 - val_accuracy: 0.7223 - val_loss: 2.5223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ca8a53cd10>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(patches, label_array, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 973ms/step - accuracy: 0.4866 - loss: 4.6618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.843190670013428, 0.46666666865348816]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=model_weights.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m weights_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save the weights\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atharva\\Anaconda3\\envs\\py_tf\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Atharva\\Anaconda3\\envs\\py_tf\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:217\u001b[0m, in \u001b[0;36msave_weights\u001b[1;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.saving.save_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(model, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m         )\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m         exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filepath)\n",
      "\u001b[1;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=model_weights.h5"
     ]
    }
   ],
   "source": [
    "weights_path = 'model_weights.h5'\n",
    "\n",
    "# Save the weights\n",
    "model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
