{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './eeg-during-mental-arithmetic-tasks-1.0.0/'\n",
    "\n",
    "rest_filepaths = []\n",
    "task_filepaths = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if filename.endswith('.edf'):\n",
    "        label = filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "        if label == '1':\n",
    "            rest_filepaths.append(filepath)\n",
    "        else:\n",
    "            task_filepaths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example function to read and process data\n",
    "def process_data(filepath):\n",
    "    data = mne.io.read_raw_edf(filepath, preload=True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=0.5, h_freq=45)\n",
    "    \n",
    "    min_t, max_t = 0, 61.99\n",
    "    data.crop(tmin=min_t, tmax=max_t)\n",
    "    \n",
    "    tmin, tmax = 0, 1.0  # Epoch duration of 1 second\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration=tmax, preload=True)\n",
    "    \n",
    "    return epochs\n",
    "\n",
    "# Function to process all 'task' labeled files\n",
    "def process_task_files(filepaths):\n",
    "    epochs_data = []  # List to store epoch data\n",
    "    labels = []  # List to store corresponding labels\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        epochs = process_data(filepath)\n",
    "        epochs_data.extend(epochs.get_data())\n",
    "        labels.extend([1] * len(epochs))  # Assign label 1 for 'task' (assuming 'task' label)\n",
    "    \n",
    "    return np.array(epochs_data), np.array(labels)\n",
    "\n",
    "def process_rest_files(filepaths):\n",
    "    epochs_data = []  # List to store epoch data\n",
    "    labels = []  # List to store corresponding labels\n",
    "    \n",
    "    for filepath in filepaths:\n",
    "        epochs = process_data(filepath)\n",
    "        epochs_data.extend(epochs.get_data())\n",
    "        labels.extend([0] * len(epochs))  # Assign label 1 for 'task' (assuming 'task' label)\n",
    "    \n",
    "    return np.array(epochs_data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rest_epochs_data, rest_labels = process_rest_files(rest_filepaths)\n",
    "\n",
    "task_epochs_data, task_labels = process_task_files(task_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2196, 21, 500), (2196, 21, 500))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_epochs_data.shape, task_epochs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2196,), (2196,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_labels.shape , task_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data_combined = np.concatenate([rest_epochs_data, task_epochs_data], axis=0)\n",
    "\n",
    "# Concatenate labels\n",
    "labels_combined = np.concatenate([rest_labels, task_labels], axis=0)\n",
    "\n",
    "# Shuffle (optional)\n",
    "# Use the same random seed for synchronizing shuffle across data and labels\n",
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "shuffle_indices = np.random.permutation(len(labels_combined))\n",
    "data = epochs_data_combined[shuffle_indices]\n",
    "label = labels_combined[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4392, 21, 500), (4392,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data.npy', data)\n",
    "np.save('label.npy', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs tensor shape: (4392, 21, 500)\n",
      "Labels tensor shape: (4392,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('data.npy')\n",
    "label = np.load('label.npy')\n",
    "\n",
    "# # Convert numpy arrays to PyTorch tensors\n",
    "# data = torch.tensor(data, dtype=torch.float32)\n",
    "# label = torch.tensor(label, dtype=torch.long)  # Assuming labels are integers (dtype=torch.long)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Epochs tensor shape:\", data.shape)\n",
    "print(\"Labels tensor shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2196)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4392, 21, 500)\n"
     ]
    }
   ],
   "source": [
    "# if isinstance(data, np.ndarray):\n",
    "#     data = data[:, np.newaxis, :, :]\n",
    "# else:\n",
    "#     data = data.unsqueeze(1).permute(0, 1, 3, 2)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train , temp_data, y_train , temp_labels = train_test_split(data, label, test_size=0.3, random_state=42)\n",
    "X_val , X_test , y_val , y_test  = train_test_split(temp_data, temp_labels, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset, SubsetRandomSampler\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train: torch.Size([3513, 1, 21, 500])\n",
      "Size of X_test: torch.Size([879, 1, 21, 500])\n",
      "Size of y_train: torch.Size([3513])\n",
      "Size of y_test: torch.Size([879])\n"
     ]
    }
   ],
   "source": [
    "# Choosing Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# # Normalizing Labels to [0, 1, 2, 3]\n",
    "# y = labels - np.min(labels)\n",
    "y = label\n",
    "\n",
    "# Normalizing Input features: z-score(mean=0, std=1)\n",
    "X = (data - np.mean(data)) / np.std(data)\n",
    "\n",
    "# Checking the existance of null & inf in the dataset\n",
    "if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n",
    "    raise ValueError(\"Data contains NaNs or infinities after normalization.\")\n",
    "if np.any(np.isnan(y)) or np.any(np.isinf(y)):\n",
    "    raise ValueError(\"Labels contain NaNs or infinities.\")\n",
    "\n",
    "# Making the X,y tensors for K-Fold Cross Validation\n",
    "X_tensor = torch.Tensor(X).unsqueeze(1)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "# Spliting  Data: 80% for Train and 20% for Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Converting to Tensor\n",
    "X_train = torch.Tensor(X_train).unsqueeze(1).to(device)\n",
    "X_test = torch.Tensor(X_test).unsqueeze(1).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device)\n",
    "y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "# Creating Tensor Dataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Printing the sizes\n",
    "print(\"Size of X_train:\", X_train.size())\n",
    "print(\"Size of X_test:\", X_test.size())\n",
    "print(\"Size of y_train:\", y_train.size())\n",
    "print(\"Size of y_test:\", y_test.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module): # EEGNET-8,2\n",
    "    def __init__(self,  chans=21, classes=2, time_points=500, f1=64, f2=16, d=2,\n",
    "                 dropoutRate=0.5, max_norm1=1, max_norm2=0.25):\n",
    "        super(EEGNet, self).__init__()\n",
    "        # Calculating FC input features\n",
    "        linear_input_size = (time_points//32)*f2\n",
    "\n",
    "        # Temporal Filters\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, f1, (1, 32), padding='same', bias=False),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            # nn.BatchNorm2d(f1, momentum=0.01, eps=1e-3),\n",
    "        )\n",
    "        # Spatial Filters\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(f1, d * f1, (chans, 1), groups=f1, bias=False), # Depthwise Conv\n",
    "            nn.BatchNorm2d(d * f1),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            nn.Dropout(dropoutRate)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(d * f1, f2, (1, 16),  groups=f2, bias=False, padding='same'), # Separable Conv\n",
    "            nn.Conv2d(f2, f2, kernel_size=1, bias=False), # Pointwise Conv\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            nn.Dropout(dropoutRate)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(linear_input_size, classes)\n",
    "\n",
    "        # Apply max_norm constraint to the depthwise layer in block2\n",
    "        self._apply_max_norm(self.block2[0], max_norm1)\n",
    "\n",
    "        # Apply max_norm constraint to the linear layer\n",
    "        self._apply_max_norm(self.fc, max_norm2)\n",
    "\n",
    "    def _apply_max_norm(self, layer, max_norm):\n",
    "        for name, param in layer.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                param.data = torch.renorm(param.data, p=2, dim=0, maxnorm=max_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 21, 500]           2,048\n",
      "       BatchNorm2d-2          [-1, 64, 21, 500]             128\n",
      "            Conv2d-3          [-1, 128, 1, 500]           2,688\n",
      "       BatchNorm2d-4          [-1, 128, 1, 500]             256\n",
      "               ELU-5          [-1, 128, 1, 500]               0\n",
      "         AvgPool2d-6          [-1, 128, 1, 125]               0\n",
      "           Dropout-7          [-1, 128, 1, 125]               0\n",
      "            Conv2d-8           [-1, 16, 1, 125]           2,048\n",
      "            Conv2d-9           [-1, 16, 1, 125]             256\n",
      "      BatchNorm2d-10           [-1, 16, 1, 125]              32\n",
      "              ELU-11           [-1, 16, 1, 125]               0\n",
      "        AvgPool2d-12            [-1, 16, 1, 15]               0\n",
      "          Dropout-13            [-1, 16, 1, 15]               0\n",
      "          Flatten-14                  [-1, 240]               0\n",
      "           Linear-15                    [-1, 2]             482\n",
      "================================================================\n",
      "Total params: 7,938\n",
      "Trainable params: 7,938\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 12.03\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 12.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_size = (1, 21, 500) \n",
    "eegnet_model = EEGNet().to(device)\n",
    "summary(eegnet_model, input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 0.6975, Accuracy: 51.55%\n",
      "Epoch 2/500, Loss: 0.6916, Accuracy: 52.92%\n",
      "Epoch 3/500, Loss: 0.6883, Accuracy: 54.63%\n",
      "Epoch 4/500, Loss: 0.6822, Accuracy: 56.96%\n",
      "Epoch 5/500, Loss: 0.6786, Accuracy: 58.04%\n",
      "Epoch 6/500, Loss: 0.6672, Accuracy: 60.20%\n",
      "Epoch 7/500, Loss: 0.6573, Accuracy: 61.97%\n",
      "Epoch 8/500, Loss: 0.6499, Accuracy: 63.08%\n",
      "Epoch 9/500, Loss: 0.6437, Accuracy: 63.73%\n",
      "Epoch 10/500, Loss: 0.6301, Accuracy: 65.13%\n",
      "Epoch 11/500, Loss: 0.6202, Accuracy: 66.58%\n",
      "Epoch 12/500, Loss: 0.6114, Accuracy: 67.52%\n",
      "Epoch 13/500, Loss: 0.6034, Accuracy: 67.55%\n",
      "Epoch 14/500, Loss: 0.5954, Accuracy: 68.46%\n",
      "Epoch 15/500, Loss: 0.5830, Accuracy: 70.08%\n",
      "Epoch 16/500, Loss: 0.5873, Accuracy: 68.86%\n",
      "Epoch 17/500, Loss: 0.5608, Accuracy: 72.25%\n",
      "Epoch 18/500, Loss: 0.5548, Accuracy: 72.33%\n",
      "Epoch 19/500, Loss: 0.5528, Accuracy: 71.90%\n",
      "Epoch 20/500, Loss: 0.5393, Accuracy: 72.50%\n",
      "Epoch 21/500, Loss: 0.5414, Accuracy: 72.16%\n",
      "Epoch 22/500, Loss: 0.5389, Accuracy: 72.16%\n",
      "Epoch 23/500, Loss: 0.5301, Accuracy: 73.95%\n",
      "Epoch 24/500, Loss: 0.5158, Accuracy: 74.44%\n",
      "Epoch 25/500, Loss: 0.5134, Accuracy: 75.12%\n",
      "Epoch 26/500, Loss: 0.5122, Accuracy: 75.32%\n",
      "Epoch 27/500, Loss: 0.5008, Accuracy: 75.63%\n",
      "Epoch 28/500, Loss: 0.4890, Accuracy: 76.60%\n",
      "Epoch 29/500, Loss: 0.4878, Accuracy: 77.48%\n",
      "Epoch 30/500, Loss: 0.4831, Accuracy: 77.11%\n",
      "Epoch 31/500, Loss: 0.4770, Accuracy: 77.20%\n",
      "Epoch 32/500, Loss: 0.4870, Accuracy: 77.03%\n",
      "Epoch 33/500, Loss: 0.4772, Accuracy: 77.26%\n",
      "Epoch 34/500, Loss: 0.4606, Accuracy: 78.59%\n",
      "Epoch 35/500, Loss: 0.4524, Accuracy: 79.90%\n",
      "Epoch 36/500, Loss: 0.4444, Accuracy: 79.65%\n",
      "Epoch 37/500, Loss: 0.4524, Accuracy: 79.50%\n",
      "Epoch 38/500, Loss: 0.4478, Accuracy: 78.82%\n",
      "Epoch 39/500, Loss: 0.4333, Accuracy: 79.65%\n",
      "Epoch 40/500, Loss: 0.4330, Accuracy: 79.85%\n",
      "Epoch 41/500, Loss: 0.4217, Accuracy: 80.61%\n",
      "Epoch 42/500, Loss: 0.4267, Accuracy: 80.16%\n",
      "Epoch 43/500, Loss: 0.4139, Accuracy: 82.21%\n",
      "Epoch 44/500, Loss: 0.4129, Accuracy: 80.76%\n",
      "Epoch 45/500, Loss: 0.4144, Accuracy: 81.07%\n",
      "Epoch 46/500, Loss: 0.4110, Accuracy: 81.41%\n",
      "Epoch 47/500, Loss: 0.4164, Accuracy: 80.76%\n",
      "Epoch 48/500, Loss: 0.4029, Accuracy: 81.92%\n",
      "Epoch 49/500, Loss: 0.4015, Accuracy: 82.15%\n",
      "Epoch 50/500, Loss: 0.3982, Accuracy: 82.61%\n",
      "Epoch 51/500, Loss: 0.3977, Accuracy: 81.84%\n",
      "Epoch 52/500, Loss: 0.3815, Accuracy: 82.86%\n",
      "Epoch 53/500, Loss: 0.3900, Accuracy: 82.21%\n",
      "Epoch 54/500, Loss: 0.3932, Accuracy: 82.10%\n",
      "Epoch 55/500, Loss: 0.3828, Accuracy: 83.21%\n",
      "Epoch 56/500, Loss: 0.3807, Accuracy: 82.81%\n",
      "Epoch 57/500, Loss: 0.3593, Accuracy: 84.23%\n",
      "Epoch 58/500, Loss: 0.3718, Accuracy: 82.95%\n",
      "Epoch 59/500, Loss: 0.3609, Accuracy: 84.49%\n",
      "Epoch 60/500, Loss: 0.3708, Accuracy: 83.77%\n",
      "Epoch 61/500, Loss: 0.3501, Accuracy: 84.32%\n",
      "Epoch 62/500, Loss: 0.3594, Accuracy: 83.89%\n",
      "Epoch 63/500, Loss: 0.3500, Accuracy: 84.46%\n",
      "Epoch 64/500, Loss: 0.3671, Accuracy: 83.29%\n",
      "Epoch 65/500, Loss: 0.3547, Accuracy: 84.20%\n",
      "Epoch 66/500, Loss: 0.3572, Accuracy: 83.95%\n",
      "Epoch 67/500, Loss: 0.3556, Accuracy: 84.03%\n",
      "Epoch 68/500, Loss: 0.3460, Accuracy: 84.77%\n",
      "Epoch 69/500, Loss: 0.3299, Accuracy: 86.36%\n",
      "Epoch 70/500, Loss: 0.3448, Accuracy: 84.83%\n",
      "Epoch 71/500, Loss: 0.3372, Accuracy: 85.43%\n",
      "Epoch 72/500, Loss: 0.3373, Accuracy: 84.94%\n",
      "Epoch 73/500, Loss: 0.3337, Accuracy: 85.06%\n",
      "Epoch 74/500, Loss: 0.3344, Accuracy: 85.06%\n",
      "Epoch 75/500, Loss: 0.3209, Accuracy: 86.17%\n",
      "Epoch 76/500, Loss: 0.3304, Accuracy: 84.74%\n",
      "Epoch 77/500, Loss: 0.3297, Accuracy: 85.34%\n",
      "Epoch 78/500, Loss: 0.3298, Accuracy: 85.43%\n",
      "Epoch 79/500, Loss: 0.3191, Accuracy: 85.77%\n",
      "Epoch 80/500, Loss: 0.3276, Accuracy: 85.82%\n",
      "Epoch 81/500, Loss: 0.3227, Accuracy: 86.17%\n",
      "Epoch 82/500, Loss: 0.3287, Accuracy: 85.60%\n",
      "Epoch 83/500, Loss: 0.3178, Accuracy: 86.59%\n",
      "Epoch 84/500, Loss: 0.3200, Accuracy: 86.19%\n",
      "Epoch 85/500, Loss: 0.3033, Accuracy: 87.08%\n",
      "Epoch 86/500, Loss: 0.2978, Accuracy: 87.45%\n",
      "Epoch 87/500, Loss: 0.3072, Accuracy: 87.02%\n",
      "Epoch 88/500, Loss: 0.3055, Accuracy: 86.82%\n",
      "Epoch 89/500, Loss: 0.3033, Accuracy: 86.11%\n",
      "Epoch 90/500, Loss: 0.3127, Accuracy: 86.68%\n",
      "Epoch 91/500, Loss: 0.2926, Accuracy: 87.50%\n",
      "Epoch 92/500, Loss: 0.2985, Accuracy: 87.48%\n",
      "Epoch 93/500, Loss: 0.3044, Accuracy: 86.99%\n",
      "Epoch 94/500, Loss: 0.3082, Accuracy: 86.05%\n",
      "Epoch 95/500, Loss: 0.2982, Accuracy: 87.53%\n",
      "Epoch 96/500, Loss: 0.2886, Accuracy: 87.36%\n",
      "Epoch 97/500, Loss: 0.3056, Accuracy: 86.82%\n",
      "Epoch 98/500, Loss: 0.2989, Accuracy: 87.56%\n",
      "Epoch 99/500, Loss: 0.2867, Accuracy: 88.41%\n",
      "Epoch 100/500, Loss: 0.2955, Accuracy: 87.59%\n",
      "Epoch 101/500, Loss: 0.2967, Accuracy: 87.53%\n",
      "Epoch 102/500, Loss: 0.2743, Accuracy: 88.44%\n",
      "Epoch 103/500, Loss: 0.3014, Accuracy: 87.42%\n",
      "Epoch 104/500, Loss: 0.2784, Accuracy: 88.16%\n",
      "Epoch 105/500, Loss: 0.2858, Accuracy: 87.70%\n",
      "Epoch 106/500, Loss: 0.2949, Accuracy: 87.45%\n",
      "Epoch 107/500, Loss: 0.2865, Accuracy: 87.30%\n",
      "Epoch 108/500, Loss: 0.2801, Accuracy: 88.13%\n",
      "Epoch 109/500, Loss: 0.2705, Accuracy: 88.87%\n",
      "Epoch 110/500, Loss: 0.2863, Accuracy: 87.67%\n",
      "Epoch 111/500, Loss: 0.2846, Accuracy: 87.25%\n",
      "Epoch 112/500, Loss: 0.2788, Accuracy: 87.90%\n",
      "Epoch 113/500, Loss: 0.2683, Accuracy: 88.73%\n",
      "Epoch 114/500, Loss: 0.2744, Accuracy: 88.70%\n",
      "Epoch 115/500, Loss: 0.2668, Accuracy: 89.10%\n",
      "Epoch 116/500, Loss: 0.2573, Accuracy: 89.18%\n",
      "Epoch 117/500, Loss: 0.2690, Accuracy: 89.04%\n",
      "Epoch 118/500, Loss: 0.2799, Accuracy: 87.59%\n",
      "Epoch 119/500, Loss: 0.2828, Accuracy: 88.56%\n",
      "Epoch 120/500, Loss: 0.2569, Accuracy: 88.96%\n",
      "Epoch 121/500, Loss: 0.2715, Accuracy: 88.76%\n",
      "Epoch 122/500, Loss: 0.2565, Accuracy: 89.38%\n",
      "Epoch 123/500, Loss: 0.2669, Accuracy: 89.10%\n",
      "Epoch 124/500, Loss: 0.2699, Accuracy: 88.64%\n",
      "Epoch 125/500, Loss: 0.2660, Accuracy: 88.73%\n",
      "Epoch 126/500, Loss: 0.2497, Accuracy: 89.58%\n",
      "Epoch 127/500, Loss: 0.2546, Accuracy: 88.70%\n",
      "Epoch 128/500, Loss: 0.2601, Accuracy: 89.30%\n",
      "Epoch 129/500, Loss: 0.2577, Accuracy: 89.50%\n",
      "Epoch 130/500, Loss: 0.2610, Accuracy: 89.13%\n",
      "Epoch 131/500, Loss: 0.2519, Accuracy: 88.78%\n",
      "Epoch 132/500, Loss: 0.2612, Accuracy: 89.10%\n",
      "Epoch 133/500, Loss: 0.2528, Accuracy: 89.21%\n",
      "Epoch 134/500, Loss: 0.2604, Accuracy: 89.21%\n",
      "Epoch 135/500, Loss: 0.2440, Accuracy: 89.87%\n",
      "Epoch 136/500, Loss: 0.2513, Accuracy: 89.61%\n",
      "Epoch 137/500, Loss: 0.2543, Accuracy: 89.64%\n",
      "Epoch 138/500, Loss: 0.2521, Accuracy: 89.44%\n",
      "Epoch 139/500, Loss: 0.2424, Accuracy: 90.12%\n",
      "Epoch 140/500, Loss: 0.2476, Accuracy: 90.07%\n",
      "Epoch 141/500, Loss: 0.2522, Accuracy: 89.67%\n",
      "Epoch 142/500, Loss: 0.2513, Accuracy: 89.98%\n",
      "Epoch 143/500, Loss: 0.2512, Accuracy: 89.33%\n",
      "Epoch 144/500, Loss: 0.2411, Accuracy: 89.92%\n",
      "Epoch 145/500, Loss: 0.2406, Accuracy: 89.52%\n",
      "Epoch 146/500, Loss: 0.2339, Accuracy: 90.46%\n",
      "Epoch 147/500, Loss: 0.2436, Accuracy: 89.64%\n",
      "Epoch 148/500, Loss: 0.2362, Accuracy: 90.41%\n",
      "Epoch 149/500, Loss: 0.2357, Accuracy: 90.15%\n",
      "Epoch 150/500, Loss: 0.2410, Accuracy: 89.95%\n",
      "Epoch 151/500, Loss: 0.2380, Accuracy: 89.87%\n",
      "Epoch 152/500, Loss: 0.2420, Accuracy: 90.15%\n",
      "Epoch 153/500, Loss: 0.2330, Accuracy: 90.09%\n",
      "Epoch 154/500, Loss: 0.2272, Accuracy: 90.49%\n",
      "Epoch 155/500, Loss: 0.2404, Accuracy: 90.29%\n",
      "Epoch 156/500, Loss: 0.2441, Accuracy: 90.04%\n",
      "Epoch 157/500, Loss: 0.2506, Accuracy: 88.81%\n",
      "Epoch 158/500, Loss: 0.2403, Accuracy: 89.78%\n",
      "Epoch 159/500, Loss: 0.2360, Accuracy: 90.07%\n",
      "Epoch 160/500, Loss: 0.2421, Accuracy: 89.78%\n",
      "Epoch 161/500, Loss: 0.2462, Accuracy: 90.12%\n",
      "Epoch 162/500, Loss: 0.2520, Accuracy: 89.07%\n",
      "Epoch 163/500, Loss: 0.2424, Accuracy: 89.64%\n",
      "Epoch 164/500, Loss: 0.2341, Accuracy: 90.41%\n",
      "Epoch 165/500, Loss: 0.2315, Accuracy: 90.26%\n",
      "Epoch 166/500, Loss: 0.2273, Accuracy: 90.81%\n",
      "Epoch 167/500, Loss: 0.2291, Accuracy: 90.55%\n",
      "Epoch 168/500, Loss: 0.2238, Accuracy: 90.92%\n",
      "Epoch 169/500, Loss: 0.2359, Accuracy: 90.46%\n",
      "Epoch 170/500, Loss: 0.2220, Accuracy: 90.86%\n",
      "Epoch 171/500, Loss: 0.2311, Accuracy: 90.89%\n",
      "Epoch 172/500, Loss: 0.2283, Accuracy: 90.04%\n",
      "Epoch 173/500, Loss: 0.2223, Accuracy: 90.69%\n",
      "Epoch 174/500, Loss: 0.2377, Accuracy: 89.78%\n",
      "Epoch 175/500, Loss: 0.2267, Accuracy: 90.52%\n",
      "Epoch 176/500, Loss: 0.2247, Accuracy: 90.66%\n",
      "Epoch 177/500, Loss: 0.2225, Accuracy: 90.98%\n",
      "Epoch 178/500, Loss: 0.2157, Accuracy: 90.55%\n",
      "Epoch 179/500, Loss: 0.2207, Accuracy: 90.95%\n",
      "Epoch 180/500, Loss: 0.2197, Accuracy: 90.86%\n",
      "Epoch 181/500, Loss: 0.2298, Accuracy: 90.58%\n",
      "Epoch 182/500, Loss: 0.2094, Accuracy: 91.72%\n",
      "Epoch 183/500, Loss: 0.2146, Accuracy: 91.37%\n",
      "Epoch 184/500, Loss: 0.2154, Accuracy: 91.12%\n",
      "Epoch 185/500, Loss: 0.2212, Accuracy: 91.37%\n",
      "Epoch 186/500, Loss: 0.2335, Accuracy: 90.38%\n",
      "Epoch 187/500, Loss: 0.2137, Accuracy: 90.83%\n",
      "Epoch 188/500, Loss: 0.2222, Accuracy: 90.26%\n",
      "Epoch 189/500, Loss: 0.2012, Accuracy: 91.69%\n",
      "Epoch 190/500, Loss: 0.2125, Accuracy: 91.20%\n",
      "Epoch 191/500, Loss: 0.2073, Accuracy: 91.57%\n",
      "Epoch 192/500, Loss: 0.2270, Accuracy: 90.24%\n",
      "Epoch 193/500, Loss: 0.2190, Accuracy: 90.58%\n",
      "Epoch 194/500, Loss: 0.1984, Accuracy: 91.89%\n",
      "Epoch 195/500, Loss: 0.2202, Accuracy: 90.55%\n",
      "Epoch 196/500, Loss: 0.2080, Accuracy: 91.37%\n",
      "Epoch 197/500, Loss: 0.2065, Accuracy: 91.40%\n",
      "Epoch 198/500, Loss: 0.2072, Accuracy: 91.92%\n",
      "Epoch 199/500, Loss: 0.2132, Accuracy: 91.26%\n",
      "Epoch 200/500, Loss: 0.2158, Accuracy: 90.86%\n",
      "Epoch 201/500, Loss: 0.2046, Accuracy: 91.43%\n",
      "Epoch 202/500, Loss: 0.2081, Accuracy: 91.09%\n",
      "Epoch 203/500, Loss: 0.2123, Accuracy: 91.43%\n",
      "Epoch 204/500, Loss: 0.2109, Accuracy: 91.60%\n",
      "Epoch 205/500, Loss: 0.1996, Accuracy: 92.09%\n",
      "Epoch 206/500, Loss: 0.2057, Accuracy: 91.66%\n",
      "Epoch 207/500, Loss: 0.2092, Accuracy: 90.75%\n",
      "Epoch 208/500, Loss: 0.2001, Accuracy: 91.49%\n",
      "Epoch 209/500, Loss: 0.2042, Accuracy: 91.63%\n",
      "Epoch 210/500, Loss: 0.2017, Accuracy: 91.74%\n",
      "Epoch 211/500, Loss: 0.2064, Accuracy: 91.46%\n",
      "Epoch 212/500, Loss: 0.1996, Accuracy: 91.94%\n",
      "Epoch 213/500, Loss: 0.2085, Accuracy: 91.09%\n",
      "Epoch 214/500, Loss: 0.1926, Accuracy: 92.88%\n",
      "Epoch 215/500, Loss: 0.1952, Accuracy: 91.80%\n",
      "Epoch 216/500, Loss: 0.2186, Accuracy: 90.95%\n",
      "Epoch 217/500, Loss: 0.1882, Accuracy: 92.37%\n",
      "Epoch 218/500, Loss: 0.2063, Accuracy: 91.52%\n",
      "Epoch 219/500, Loss: 0.2057, Accuracy: 91.26%\n",
      "Epoch 220/500, Loss: 0.2038, Accuracy: 91.26%\n",
      "Epoch 221/500, Loss: 0.2034, Accuracy: 90.95%\n",
      "Epoch 222/500, Loss: 0.2078, Accuracy: 91.43%\n",
      "Epoch 223/500, Loss: 0.2026, Accuracy: 92.20%\n",
      "Epoch 224/500, Loss: 0.2016, Accuracy: 91.63%\n",
      "Epoch 225/500, Loss: 0.2052, Accuracy: 91.03%\n",
      "Epoch 226/500, Loss: 0.1963, Accuracy: 91.89%\n",
      "Epoch 227/500, Loss: 0.2012, Accuracy: 91.29%\n",
      "Epoch 228/500, Loss: 0.1973, Accuracy: 92.17%\n",
      "Epoch 229/500, Loss: 0.1914, Accuracy: 92.09%\n",
      "Epoch 230/500, Loss: 0.1942, Accuracy: 91.86%\n",
      "Epoch 231/500, Loss: 0.2033, Accuracy: 91.40%\n",
      "Epoch 232/500, Loss: 0.1933, Accuracy: 91.94%\n",
      "Epoch 233/500, Loss: 0.1947, Accuracy: 91.80%\n",
      "Epoch 234/500, Loss: 0.2001, Accuracy: 91.77%\n",
      "Epoch 235/500, Loss: 0.1900, Accuracy: 92.00%\n",
      "Epoch 236/500, Loss: 0.1933, Accuracy: 92.66%\n",
      "Epoch 237/500, Loss: 0.1934, Accuracy: 92.23%\n",
      "Epoch 238/500, Loss: 0.1948, Accuracy: 92.00%\n",
      "Epoch 239/500, Loss: 0.1991, Accuracy: 91.52%\n",
      "Epoch 240/500, Loss: 0.1970, Accuracy: 91.52%\n",
      "Epoch 241/500, Loss: 0.1864, Accuracy: 93.03%\n",
      "Epoch 242/500, Loss: 0.1986, Accuracy: 92.03%\n",
      "Epoch 243/500, Loss: 0.1889, Accuracy: 92.68%\n",
      "Epoch 244/500, Loss: 0.1901, Accuracy: 92.40%\n",
      "Epoch 245/500, Loss: 0.1806, Accuracy: 92.71%\n",
      "Epoch 246/500, Loss: 0.1895, Accuracy: 92.26%\n",
      "Epoch 247/500, Loss: 0.2013, Accuracy: 91.52%\n",
      "Epoch 248/500, Loss: 0.2038, Accuracy: 91.72%\n",
      "Epoch 249/500, Loss: 0.1867, Accuracy: 92.54%\n",
      "Epoch 250/500, Loss: 0.1851, Accuracy: 92.74%\n",
      "Epoch 251/500, Loss: 0.1883, Accuracy: 92.14%\n",
      "Epoch 252/500, Loss: 0.1875, Accuracy: 92.12%\n",
      "Epoch 253/500, Loss: 0.1934, Accuracy: 92.00%\n",
      "Epoch 254/500, Loss: 0.1941, Accuracy: 91.63%\n",
      "Epoch 255/500, Loss: 0.1903, Accuracy: 91.83%\n",
      "Epoch 256/500, Loss: 0.1830, Accuracy: 92.63%\n",
      "Epoch 257/500, Loss: 0.1844, Accuracy: 92.77%\n",
      "Epoch 258/500, Loss: 0.1885, Accuracy: 92.12%\n",
      "Epoch 259/500, Loss: 0.1906, Accuracy: 92.29%\n",
      "Epoch 260/500, Loss: 0.1787, Accuracy: 93.00%\n",
      "Epoch 261/500, Loss: 0.1752, Accuracy: 92.49%\n",
      "Epoch 262/500, Loss: 0.1840, Accuracy: 92.57%\n",
      "Epoch 263/500, Loss: 0.1834, Accuracy: 92.77%\n",
      "Epoch 264/500, Loss: 0.1889, Accuracy: 92.43%\n",
      "Epoch 265/500, Loss: 0.1735, Accuracy: 93.25%\n",
      "Epoch 266/500, Loss: 0.2001, Accuracy: 92.29%\n",
      "Epoch 267/500, Loss: 0.1826, Accuracy: 92.60%\n",
      "Epoch 268/500, Loss: 0.1852, Accuracy: 92.43%\n",
      "Epoch 269/500, Loss: 0.1753, Accuracy: 93.03%\n",
      "Epoch 270/500, Loss: 0.2002, Accuracy: 91.60%\n",
      "Epoch 271/500, Loss: 0.1845, Accuracy: 92.29%\n",
      "Epoch 272/500, Loss: 0.1810, Accuracy: 92.83%\n",
      "Epoch 273/500, Loss: 0.1834, Accuracy: 92.51%\n",
      "Epoch 274/500, Loss: 0.1748, Accuracy: 92.66%\n",
      "Epoch 275/500, Loss: 0.1816, Accuracy: 92.97%\n",
      "Epoch 276/500, Loss: 0.1879, Accuracy: 92.14%\n",
      "Epoch 277/500, Loss: 0.1916, Accuracy: 92.09%\n",
      "Epoch 278/500, Loss: 0.1858, Accuracy: 92.34%\n",
      "Epoch 279/500, Loss: 0.1865, Accuracy: 92.29%\n",
      "Epoch 280/500, Loss: 0.1828, Accuracy: 92.68%\n",
      "Epoch 281/500, Loss: 0.1722, Accuracy: 93.00%\n",
      "Epoch 282/500, Loss: 0.1837, Accuracy: 92.74%\n",
      "Epoch 283/500, Loss: 0.1741, Accuracy: 93.11%\n",
      "Epoch 284/500, Loss: 0.1622, Accuracy: 94.05%\n",
      "Epoch 285/500, Loss: 0.1903, Accuracy: 92.06%\n",
      "Epoch 286/500, Loss: 0.1801, Accuracy: 92.80%\n",
      "Epoch 287/500, Loss: 0.1783, Accuracy: 92.26%\n",
      "Epoch 288/500, Loss: 0.1715, Accuracy: 92.83%\n",
      "Epoch 289/500, Loss: 0.1722, Accuracy: 92.88%\n",
      "Epoch 290/500, Loss: 0.1804, Accuracy: 92.51%\n",
      "Epoch 291/500, Loss: 0.1821, Accuracy: 92.23%\n",
      "Epoch 292/500, Loss: 0.1803, Accuracy: 92.71%\n",
      "Epoch 293/500, Loss: 0.1773, Accuracy: 92.91%\n",
      "Epoch 294/500, Loss: 0.1858, Accuracy: 92.74%\n",
      "Epoch 295/500, Loss: 0.1759, Accuracy: 92.68%\n",
      "Epoch 296/500, Loss: 0.1784, Accuracy: 93.34%\n",
      "Epoch 297/500, Loss: 0.1877, Accuracy: 92.14%\n",
      "Epoch 298/500, Loss: 0.1678, Accuracy: 93.08%\n",
      "Epoch 299/500, Loss: 0.1742, Accuracy: 93.05%\n",
      "Epoch 300/500, Loss: 0.1809, Accuracy: 93.17%\n",
      "Epoch 301/500, Loss: 0.1774, Accuracy: 92.71%\n",
      "Epoch 302/500, Loss: 0.1639, Accuracy: 93.48%\n",
      "Epoch 303/500, Loss: 0.1813, Accuracy: 92.77%\n",
      "Epoch 304/500, Loss: 0.1756, Accuracy: 93.11%\n",
      "Epoch 305/500, Loss: 0.1769, Accuracy: 92.80%\n",
      "Epoch 306/500, Loss: 0.1781, Accuracy: 92.80%\n",
      "Epoch 307/500, Loss: 0.1735, Accuracy: 93.03%\n",
      "Epoch 308/500, Loss: 0.1699, Accuracy: 92.97%\n",
      "Epoch 309/500, Loss: 0.1689, Accuracy: 93.25%\n",
      "Epoch 310/500, Loss: 0.1886, Accuracy: 91.83%\n",
      "Epoch 311/500, Loss: 0.1731, Accuracy: 92.57%\n",
      "Epoch 312/500, Loss: 0.1655, Accuracy: 92.97%\n",
      "Epoch 313/500, Loss: 0.1736, Accuracy: 92.68%\n",
      "Epoch 314/500, Loss: 0.1774, Accuracy: 92.51%\n",
      "Epoch 315/500, Loss: 0.1899, Accuracy: 91.94%\n",
      "Epoch 316/500, Loss: 0.1764, Accuracy: 92.63%\n",
      "Epoch 317/500, Loss: 0.1627, Accuracy: 93.42%\n",
      "Epoch 318/500, Loss: 0.1782, Accuracy: 92.91%\n",
      "Epoch 319/500, Loss: 0.1697, Accuracy: 92.94%\n",
      "Epoch 320/500, Loss: 0.1671, Accuracy: 93.37%\n",
      "Epoch 321/500, Loss: 0.1666, Accuracy: 93.37%\n",
      "Epoch 322/500, Loss: 0.1697, Accuracy: 92.94%\n",
      "Epoch 323/500, Loss: 0.1672, Accuracy: 93.23%\n",
      "Epoch 324/500, Loss: 0.1688, Accuracy: 93.34%\n",
      "Epoch 325/500, Loss: 0.1707, Accuracy: 93.00%\n",
      "Epoch 326/500, Loss: 0.1708, Accuracy: 92.88%\n",
      "Epoch 327/500, Loss: 0.1737, Accuracy: 92.94%\n",
      "Epoch 328/500, Loss: 0.1800, Accuracy: 92.86%\n",
      "Epoch 329/500, Loss: 0.1677, Accuracy: 93.00%\n",
      "Epoch 330/500, Loss: 0.1657, Accuracy: 93.65%\n",
      "Epoch 331/500, Loss: 0.1695, Accuracy: 93.05%\n",
      "Epoch 332/500, Loss: 0.1644, Accuracy: 93.05%\n",
      "Epoch 333/500, Loss: 0.1628, Accuracy: 93.62%\n",
      "Epoch 334/500, Loss: 0.1766, Accuracy: 93.08%\n",
      "Epoch 335/500, Loss: 0.1703, Accuracy: 93.14%\n",
      "Epoch 336/500, Loss: 0.1675, Accuracy: 92.71%\n",
      "Epoch 337/500, Loss: 0.1601, Accuracy: 93.79%\n",
      "Epoch 338/500, Loss: 0.1701, Accuracy: 93.14%\n",
      "Epoch 339/500, Loss: 0.1763, Accuracy: 92.86%\n",
      "Epoch 340/500, Loss: 0.1682, Accuracy: 93.42%\n",
      "Epoch 341/500, Loss: 0.1607, Accuracy: 93.08%\n",
      "Epoch 342/500, Loss: 0.1579, Accuracy: 93.51%\n",
      "Epoch 343/500, Loss: 0.1552, Accuracy: 94.08%\n",
      "Epoch 344/500, Loss: 0.1676, Accuracy: 93.20%\n",
      "Epoch 345/500, Loss: 0.1734, Accuracy: 92.31%\n",
      "Epoch 346/500, Loss: 0.1613, Accuracy: 93.54%\n",
      "Epoch 347/500, Loss: 0.1605, Accuracy: 93.79%\n",
      "Epoch 348/500, Loss: 0.1646, Accuracy: 93.03%\n",
      "Epoch 349/500, Loss: 0.1753, Accuracy: 92.77%\n",
      "Epoch 350/500, Loss: 0.1639, Accuracy: 93.51%\n",
      "Epoch 351/500, Loss: 0.1705, Accuracy: 92.57%\n",
      "Epoch 352/500, Loss: 0.1609, Accuracy: 93.37%\n",
      "Epoch 353/500, Loss: 0.1676, Accuracy: 93.25%\n",
      "Epoch 354/500, Loss: 0.1663, Accuracy: 93.14%\n",
      "Epoch 355/500, Loss: 0.1608, Accuracy: 93.88%\n",
      "Epoch 356/500, Loss: 0.1674, Accuracy: 93.23%\n",
      "Epoch 357/500, Loss: 0.1553, Accuracy: 94.02%\n",
      "Epoch 358/500, Loss: 0.1632, Accuracy: 93.08%\n",
      "Epoch 359/500, Loss: 0.1673, Accuracy: 93.25%\n",
      "Epoch 360/500, Loss: 0.1629, Accuracy: 92.66%\n",
      "Epoch 361/500, Loss: 0.1555, Accuracy: 93.11%\n",
      "Epoch 362/500, Loss: 0.1569, Accuracy: 93.65%\n",
      "Epoch 363/500, Loss: 0.1510, Accuracy: 94.11%\n",
      "Epoch 364/500, Loss: 0.1607, Accuracy: 94.02%\n",
      "Epoch 365/500, Loss: 0.1569, Accuracy: 93.31%\n",
      "Epoch 366/500, Loss: 0.1643, Accuracy: 93.23%\n",
      "Epoch 367/500, Loss: 0.1604, Accuracy: 93.00%\n",
      "Epoch 368/500, Loss: 0.1569, Accuracy: 93.77%\n",
      "Epoch 369/500, Loss: 0.1630, Accuracy: 93.60%\n",
      "Epoch 370/500, Loss: 0.1503, Accuracy: 93.88%\n",
      "Epoch 371/500, Loss: 0.1688, Accuracy: 93.08%\n",
      "Epoch 372/500, Loss: 0.1626, Accuracy: 93.57%\n",
      "Epoch 373/500, Loss: 0.1609, Accuracy: 93.20%\n",
      "Epoch 374/500, Loss: 0.1489, Accuracy: 94.14%\n",
      "Epoch 375/500, Loss: 0.1609, Accuracy: 93.40%\n",
      "Epoch 376/500, Loss: 0.1636, Accuracy: 93.37%\n",
      "Epoch 377/500, Loss: 0.1564, Accuracy: 94.16%\n",
      "Epoch 378/500, Loss: 0.1594, Accuracy: 93.31%\n",
      "Epoch 379/500, Loss: 0.1611, Accuracy: 93.25%\n",
      "Epoch 380/500, Loss: 0.1673, Accuracy: 93.05%\n",
      "Epoch 381/500, Loss: 0.1588, Accuracy: 93.97%\n",
      "Epoch 382/500, Loss: 0.1459, Accuracy: 94.34%\n",
      "Epoch 383/500, Loss: 0.1703, Accuracy: 92.86%\n",
      "Epoch 384/500, Loss: 0.1584, Accuracy: 93.57%\n",
      "Epoch 385/500, Loss: 0.1604, Accuracy: 93.14%\n",
      "Epoch 386/500, Loss: 0.1603, Accuracy: 93.77%\n",
      "Epoch 387/500, Loss: 0.1601, Accuracy: 93.51%\n",
      "Epoch 388/500, Loss: 0.1582, Accuracy: 93.42%\n",
      "Epoch 389/500, Loss: 0.1694, Accuracy: 93.17%\n",
      "Epoch 390/500, Loss: 0.1504, Accuracy: 94.45%\n",
      "Epoch 391/500, Loss: 0.1486, Accuracy: 93.57%\n",
      "Epoch 392/500, Loss: 0.1613, Accuracy: 93.45%\n",
      "Epoch 393/500, Loss: 0.1538, Accuracy: 94.02%\n",
      "Epoch 394/500, Loss: 0.1514, Accuracy: 94.11%\n",
      "Epoch 395/500, Loss: 0.1572, Accuracy: 93.57%\n",
      "Epoch 396/500, Loss: 0.1512, Accuracy: 94.19%\n",
      "Epoch 397/500, Loss: 0.1521, Accuracy: 93.85%\n",
      "Epoch 398/500, Loss: 0.1564, Accuracy: 93.57%\n",
      "Epoch 399/500, Loss: 0.1613, Accuracy: 93.42%\n",
      "Epoch 400/500, Loss: 0.1540, Accuracy: 94.16%\n",
      "Epoch 401/500, Loss: 0.1661, Accuracy: 93.88%\n",
      "Epoch 402/500, Loss: 0.1606, Accuracy: 93.28%\n",
      "Epoch 403/500, Loss: 0.1675, Accuracy: 93.48%\n",
      "Epoch 404/500, Loss: 0.1588, Accuracy: 93.79%\n",
      "Epoch 405/500, Loss: 0.1610, Accuracy: 93.77%\n",
      "Epoch 406/500, Loss: 0.1515, Accuracy: 93.79%\n",
      "Epoch 407/500, Loss: 0.1521, Accuracy: 93.54%\n",
      "Epoch 408/500, Loss: 0.1530, Accuracy: 94.05%\n",
      "Epoch 409/500, Loss: 0.1457, Accuracy: 94.31%\n",
      "Epoch 410/500, Loss: 0.1467, Accuracy: 94.16%\n",
      "Epoch 411/500, Loss: 0.1516, Accuracy: 93.82%\n",
      "Epoch 412/500, Loss: 0.1504, Accuracy: 93.57%\n",
      "Epoch 413/500, Loss: 0.1489, Accuracy: 93.65%\n",
      "Epoch 414/500, Loss: 0.1415, Accuracy: 94.16%\n",
      "Epoch 415/500, Loss: 0.1512, Accuracy: 93.60%\n",
      "Epoch 416/500, Loss: 0.1574, Accuracy: 93.94%\n",
      "Epoch 417/500, Loss: 0.1474, Accuracy: 94.28%\n",
      "Epoch 418/500, Loss: 0.1561, Accuracy: 93.62%\n",
      "Epoch 419/500, Loss: 0.1517, Accuracy: 93.37%\n",
      "Epoch 420/500, Loss: 0.1405, Accuracy: 94.19%\n",
      "Epoch 421/500, Loss: 0.1457, Accuracy: 93.99%\n",
      "Epoch 422/500, Loss: 0.1526, Accuracy: 93.91%\n",
      "Epoch 423/500, Loss: 0.1557, Accuracy: 93.54%\n",
      "Epoch 424/500, Loss: 0.1687, Accuracy: 92.97%\n",
      "Epoch 425/500, Loss: 0.1560, Accuracy: 93.74%\n",
      "Epoch 426/500, Loss: 0.1540, Accuracy: 94.08%\n",
      "Epoch 427/500, Loss: 0.1518, Accuracy: 93.91%\n",
      "Epoch 428/500, Loss: 0.1505, Accuracy: 93.51%\n",
      "Epoch 429/500, Loss: 0.1447, Accuracy: 93.71%\n",
      "Epoch 430/500, Loss: 0.1612, Accuracy: 93.25%\n",
      "Epoch 431/500, Loss: 0.1500, Accuracy: 93.94%\n",
      "Epoch 432/500, Loss: 0.1473, Accuracy: 94.08%\n",
      "Epoch 433/500, Loss: 0.1464, Accuracy: 93.68%\n",
      "Epoch 434/500, Loss: 0.1434, Accuracy: 93.91%\n",
      "Epoch 435/500, Loss: 0.1477, Accuracy: 94.22%\n",
      "Epoch 436/500, Loss: 0.1489, Accuracy: 93.82%\n",
      "Epoch 437/500, Loss: 0.1519, Accuracy: 93.82%\n",
      "Epoch 438/500, Loss: 0.1335, Accuracy: 94.39%\n",
      "Epoch 439/500, Loss: 0.1526, Accuracy: 94.08%\n",
      "Epoch 440/500, Loss: 0.1552, Accuracy: 94.14%\n",
      "Epoch 441/500, Loss: 0.1524, Accuracy: 94.22%\n",
      "Epoch 442/500, Loss: 0.1506, Accuracy: 93.97%\n",
      "Epoch 443/500, Loss: 0.1505, Accuracy: 94.05%\n",
      "Epoch 444/500, Loss: 0.1581, Accuracy: 93.88%\n",
      "Epoch 445/500, Loss: 0.1549, Accuracy: 93.71%\n",
      "Epoch 446/500, Loss: 0.1438, Accuracy: 94.68%\n",
      "Epoch 447/500, Loss: 0.1471, Accuracy: 94.31%\n",
      "Epoch 448/500, Loss: 0.1507, Accuracy: 94.11%\n",
      "Epoch 449/500, Loss: 0.1416, Accuracy: 94.22%\n",
      "Epoch 450/500, Loss: 0.1431, Accuracy: 94.45%\n",
      "Epoch 451/500, Loss: 0.1513, Accuracy: 94.11%\n",
      "Epoch 452/500, Loss: 0.1459, Accuracy: 94.05%\n",
      "Epoch 453/500, Loss: 0.1504, Accuracy: 94.31%\n",
      "Epoch 454/500, Loss: 0.1483, Accuracy: 94.16%\n",
      "Epoch 455/500, Loss: 0.1398, Accuracy: 94.45%\n",
      "Epoch 456/500, Loss: 0.1358, Accuracy: 94.71%\n",
      "Epoch 457/500, Loss: 0.1272, Accuracy: 94.82%\n",
      "Epoch 458/500, Loss: 0.1389, Accuracy: 94.08%\n",
      "Epoch 459/500, Loss: 0.1436, Accuracy: 94.59%\n",
      "Epoch 460/500, Loss: 0.1430, Accuracy: 94.14%\n",
      "Epoch 461/500, Loss: 0.1375, Accuracy: 94.42%\n",
      "Epoch 462/500, Loss: 0.1542, Accuracy: 93.85%\n",
      "Epoch 463/500, Loss: 0.1517, Accuracy: 94.22%\n",
      "Epoch 464/500, Loss: 0.1544, Accuracy: 93.79%\n",
      "Epoch 465/500, Loss: 0.1483, Accuracy: 94.25%\n",
      "Epoch 466/500, Loss: 0.1383, Accuracy: 94.56%\n",
      "Epoch 467/500, Loss: 0.1471, Accuracy: 94.08%\n",
      "Epoch 468/500, Loss: 0.1445, Accuracy: 94.31%\n",
      "Epoch 469/500, Loss: 0.1375, Accuracy: 94.48%\n",
      "Epoch 470/500, Loss: 0.1346, Accuracy: 94.62%\n",
      "Epoch 471/500, Loss: 0.1483, Accuracy: 93.94%\n",
      "Epoch 472/500, Loss: 0.1393, Accuracy: 94.39%\n",
      "Epoch 473/500, Loss: 0.1344, Accuracy: 94.82%\n",
      "Epoch 474/500, Loss: 0.1247, Accuracy: 95.02%\n",
      "Epoch 475/500, Loss: 0.1332, Accuracy: 95.05%\n",
      "Epoch 476/500, Loss: 0.1479, Accuracy: 93.88%\n",
      "Epoch 477/500, Loss: 0.1423, Accuracy: 94.28%\n",
      "Epoch 478/500, Loss: 0.1554, Accuracy: 93.51%\n",
      "Epoch 479/500, Loss: 0.1381, Accuracy: 94.25%\n",
      "Epoch 480/500, Loss: 0.1327, Accuracy: 94.39%\n",
      "Epoch 481/500, Loss: 0.1399, Accuracy: 94.82%\n",
      "Epoch 482/500, Loss: 0.1507, Accuracy: 94.02%\n",
      "Epoch 483/500, Loss: 0.1468, Accuracy: 93.88%\n",
      "Epoch 484/500, Loss: 0.1413, Accuracy: 94.42%\n",
      "Epoch 485/500, Loss: 0.1445, Accuracy: 94.39%\n",
      "Epoch 486/500, Loss: 0.1350, Accuracy: 94.11%\n",
      "Epoch 487/500, Loss: 0.1442, Accuracy: 94.05%\n",
      "Epoch 488/500, Loss: 0.1314, Accuracy: 94.90%\n",
      "Epoch 489/500, Loss: 0.1498, Accuracy: 94.22%\n",
      "Epoch 490/500, Loss: 0.1315, Accuracy: 95.02%\n",
      "Epoch 491/500, Loss: 0.1352, Accuracy: 94.96%\n",
      "Epoch 492/500, Loss: 0.1264, Accuracy: 95.08%\n",
      "Epoch 493/500, Loss: 0.1460, Accuracy: 93.85%\n",
      "Epoch 494/500, Loss: 0.1513, Accuracy: 94.22%\n",
      "Epoch 495/500, Loss: 0.1306, Accuracy: 94.53%\n",
      "Epoch 496/500, Loss: 0.1340, Accuracy: 94.76%\n",
      "Epoch 497/500, Loss: 0.1415, Accuracy: 94.22%\n",
      "Epoch 498/500, Loss: 0.1456, Accuracy: 94.22%\n",
      "Epoch 499/500, Loss: 0.1340, Accuracy: 95.10%\n",
      "Epoch 500/500, Loss: 0.1354, Accuracy: 94.45%\n",
      "Average Loss: 0.13539370512677298\n"
     ]
    }
   ],
   "source": [
    "eegnet_model = EEGNet().to(device)\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(eegnet_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 512\n",
    "for epoch in range(num_epochs):\n",
    "    eegnet_model.train()\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        inputs = X_train[i:i+batch_size].to(device)\n",
    "        labels = y_train[i:i+batch_size].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = eegnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(X_train)\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {(epoch_accuracy*100):.2f}%\")\n",
    "average_loss = running_loss / len(X_train)\n",
    "print(\"Average Loss:\", average_loss)\n",
    "\n",
    "# Saving model\n",
    "torch.save(eegnet_model, 'eegnet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.04%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eegnet_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        inputs = X_test[i:i+1].to(device)\n",
    "        labels = y_test[i:i+1].to(device)\n",
    "        outputs = eegnet_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = (correct / total)*100\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eegnet_model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "classes = ['rest', 'task']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in zip(X_test, y_test):\n",
    "        outputs = eegnet_model(inputs.unsqueeze(0))  # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(predicted.item())\n",
    "        y_true.append(labels.item())\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "cf_matrix = cf_matrix.astype('float') / cf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "df_cm = pd.DataFrame(cf_matrix, index=classes, columns=classes)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sn.heatmap(df_cm, annot=True, cmap='Blues', fmt='.2f')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix_eegnet.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
