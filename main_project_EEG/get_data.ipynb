{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './eeg-during-mental-arithmetic-tasks-1.0.0/'\n",
    "\n",
    "rest_filepaths = []\n",
    "task_filepaths = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    if filename.endswith('.edf'):\n",
    "        label = filename.split('_')[-1].split('.')[0]\n",
    "\n",
    "        if label == '1':\n",
    "            rest_filepaths.append(filepath)\n",
    "        else:\n",
    "            task_filepaths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rest_filepaths), len(task_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_epochs = 81\n",
    "\n",
    "\n",
    "def read_data(filepath):\n",
    "    data = mne.io.read_raw_edf(filepath, preload=True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq=0.5, h_freq=45)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration=5, overlap=1)\n",
    "    array = epochs.get_data()\n",
    "\n",
    "    # if array.shape[0]>121:\n",
    "    #     array = resample(array, replace=False, n_samples=average_epochs, random_state=42)\n",
    "    # else:\n",
    "    #     # Oversample 'task' epochs to the average value\n",
    "    #     array = resample(array, replace=True, n_samples=average_epochs, random_state=42)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rest_epochs_array = [read_data(filepath) for filepath in rest_filepaths]\n",
    "task_epochs_array = [read_data(filepath) for filepath in task_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 21, 2500), (15, 21, 2500))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_epochs_array[0].shape, task_epochs_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels:\n",
    "rest_label = [len(i)*[0] for i in rest_epochs_array]\n",
    "task_label = [len(i)*[1] for i in task_epochs_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(task_label), len(task_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs = rest_epochs_array + task_epochs_array\n",
    "all_labels = rest_label + task_label\n",
    "\n",
    "# perm = np.random.permutation(72)\n",
    "\n",
    "# # Shuffle both arrays using the same permutation along the first axis\n",
    "# shuffled_epochs = []\n",
    "# shuffled_labels= []\n",
    "\n",
    "# for index in perm:\n",
    "#     shuffled_epochs.append(all_epochs[index])\n",
    "#     shuffled_labels.append(all_labels[index])\n",
    "\n",
    "# all_epochs = shuffled_epochs\n",
    "# all_labels = shuffled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 45, 21, 2500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_epochs), len(all_epochs[0]), len(\n",
    "    all_epochs[0][0]), len(all_epochs[0][0][0]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 45)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels), len(all_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 72)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_epochs), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list = [[i]*len(j) for i, j in enumerate(all_epochs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 72, 72)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_list), len(all_epochs), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.vstack(all_epochs)\n",
    "label_array = np.hstack(all_labels)\n",
    "group_array = np.hstack(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2132, 21, 2500) (2132,) (2132,)\n"
     ]
    }
   ],
   "source": [
    "print(data_array.shape, label_array.shape, group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 2500, 21)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.moveaxis(data_array, 1, 2)\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAY TO TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def EEGNet(nb_classes, Chans=64, Samples=128,\n",
    "           dropoutRate=0.5, kernLength=64, F1=8,\n",
    "           D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    input1 = Input(shape=(Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1 = Conv2D(F1, (1, kernLength), padding='same',\n",
    "                    input_shape=(Chans, Samples, 1),\n",
    "                    use_bias=False)(input1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = DepthwiseConv2D((Chans, 1), use_bias=False,\n",
    "                             depth_multiplier=D,\n",
    "                             depthwise_constraint=max_norm(1.))(block1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = Activation('elu')(block1)\n",
    "    block1 = AveragePooling2D((1, 4))(block1)\n",
    "    block1 = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2 = SeparableConv2D(F2, (1, 16),\n",
    "                             use_bias=False, padding='same')(block1)\n",
    "    block2 = BatchNormalization()(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = AveragePooling2D((1, 8))(block2)\n",
    "    block2 = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten = Flatten(name='flatten')(block2)\n",
    "\n",
    "    dense = Dense(nb_classes, name='dense',\n",
    "                  kernel_constraint=max_norm(norm_rate))(flatten)\n",
    "    softmax = Activation('softmax', name='softmax')(dense)\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gkf = GroupKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = []\n",
    "\n",
    "# for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "#     train_features, train_labels = data_array[train_index], label_array[train_index]\n",
    "#     val_features, val_labels = data_array[val_index], label_array[val_index]\n",
    "\n",
    "#     train_labels_onehot = np.zeros((train_labels.size, 2))\n",
    "#     train_labels_onehot[np.arange(train_labels.size), train_labels] = 1\n",
    "\n",
    "#     val_labels_onehot = np.zeros((val_labels.size, 2))\n",
    "#     val_labels_onehot[np.arange(val_labels.size), val_labels] = 1\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "#     val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "\n",
    "#     train_features = np.moveaxis(train_features,1,2)\n",
    "#     val_features = np.moveaxis(val_features,1,2)\n",
    "\n",
    "#     train_features = np.reshape(train_features, (*train_features.shape, 1))\n",
    "#     val_features = np.reshape(val_features, (*val_features.shape, 1))\n",
    "\n",
    "#     model = EEGNet(2, Chans=21, Samples=1000)\n",
    "\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='binary_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     model.fit(train_features, train_labels_onehot, epochs =10, batch_size = 128)\n",
    "\n",
    "#     accuracy.append(model.evaluate(val_features, val_labels_onehot)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2s/step - accuracy: 0.6201 - loss: 0.6784 - val_accuracy: 0.7573 - val_loss: 0.6865\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.7443 - loss: 0.5452 - val_accuracy: 0.2924 - val_loss: 0.6982\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.7573 - loss: 0.5129 - val_accuracy: 0.2953 - val_loss: 0.6996\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.7738 - loss: 0.4754 - val_accuracy: 0.3187 - val_loss: 0.7036\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.8047 - loss: 0.4200 - val_accuracy: 0.3216 - val_loss: 0.7085\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8097 - loss: 0.4004 - val_accuracy: 0.4620 - val_loss: 0.6944\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8424 - loss: 0.3554 - val_accuracy: 0.5789 - val_loss: 0.6784\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8839 - loss: 0.2872 - val_accuracy: 0.7719 - val_loss: 0.5881\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9052 - loss: 0.2427 - val_accuracy: 0.7719 - val_loss: 0.5160\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9309 - loss: 0.2024 - val_accuracy: 0.7836 - val_loss: 0.4689\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 332ms/step - accuracy: 0.9487 - loss: 0.3098\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6306 - loss: 0.6765 - val_accuracy: 0.7735 - val_loss: 0.6711\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7512 - loss: 0.5331 - val_accuracy: 0.7706 - val_loss: 0.6793\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7657 - loss: 0.4797 - val_accuracy: 0.7676 - val_loss: 0.6736\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8123 - loss: 0.4189 - val_accuracy: 0.7735 - val_loss: 0.6401\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8681 - loss: 0.3432 - val_accuracy: 0.7735 - val_loss: 0.5900\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8910 - loss: 0.2894 - val_accuracy: 0.7735 - val_loss: 0.5231\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9229 - loss: 0.2148 - val_accuracy: 0.7735 - val_loss: 0.5168\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9592 - loss: 0.1634 - val_accuracy: 0.7735 - val_loss: 0.5883\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9539 - loss: 0.1449 - val_accuracy: 0.7735 - val_loss: 0.7090\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9687 - loss: 0.1180 - val_accuracy: 0.7735 - val_loss: 0.9076\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 332ms/step - accuracy: 0.9270 - loss: 0.3559\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.6610 - loss: 0.6597 - val_accuracy: 0.7412 - val_loss: 0.6754\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7525 - loss: 0.5244 - val_accuracy: 0.7441 - val_loss: 0.6857\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7845 - loss: 0.4779 - val_accuracy: 0.7529 - val_loss: 0.6813\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7793 - loss: 0.4419 - val_accuracy: 0.7382 - val_loss: 0.6743\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8067 - loss: 0.3973 - val_accuracy: 0.7471 - val_loss: 0.6587\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8428 - loss: 0.3492 - val_accuracy: 0.7441 - val_loss: 0.6324\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.8782 - loss: 0.2913 - val_accuracy: 0.7412 - val_loss: 0.5698\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9156 - loss: 0.2319 - val_accuracy: 0.7412 - val_loss: 0.5210\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9454 - loss: 0.1818 - val_accuracy: 0.7412 - val_loss: 0.4986\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9642 - loss: 0.1513 - val_accuracy: 0.7412 - val_loss: 0.5094\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 342ms/step - accuracy: 0.9270 - loss: 0.2827\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6281 - loss: 0.6846 - val_accuracy: 0.7522 - val_loss: 0.6782\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7292 - loss: 0.5351 - val_accuracy: 0.2770 - val_loss: 0.6989\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.7648 - loss: 0.4775 - val_accuracy: 0.4461 - val_loss: 0.6943\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7757 - loss: 0.4397 - val_accuracy: 0.4431 - val_loss: 0.6969\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.8343 - loss: 0.3785 - val_accuracy: 0.7289 - val_loss: 0.6691\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8585 - loss: 0.3162 - val_accuracy: 0.7609 - val_loss: 0.6146\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9280 - loss: 0.2265 - val_accuracy: 0.7580 - val_loss: 0.5508\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9294 - loss: 0.2099 - val_accuracy: 0.7580 - val_loss: 0.5011\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9467 - loss: 0.1566 - val_accuracy: 0.7551 - val_loss: 0.4902\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9553 - loss: 0.1315 - val_accuracy: 0.7551 - val_loss: 0.5341\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 318ms/step - accuracy: 0.9305 - loss: 0.2808\n",
      "Epoch 1/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6194 - loss: 0.6957 - val_accuracy: 0.7318 - val_loss: 0.6808\n",
      "Epoch 2/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.7536 - loss: 0.5118 - val_accuracy: 0.3440 - val_loss: 0.6954\n",
      "Epoch 3/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7934 - loss: 0.4536 - val_accuracy: 0.5539 - val_loss: 0.6917\n",
      "Epoch 4/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8270 - loss: 0.3983 - val_accuracy: 0.6181 - val_loss: 0.6878\n",
      "Epoch 5/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8494 - loss: 0.3402 - val_accuracy: 0.7522 - val_loss: 0.6663\n",
      "Epoch 6/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8946 - loss: 0.2674 - val_accuracy: 0.7609 - val_loss: 0.6414\n",
      "Epoch 7/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.9183 - loss: 0.2261 - val_accuracy: 0.7580 - val_loss: 0.6026\n",
      "Epoch 8/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step - accuracy: 0.9336 - loss: 0.1985 - val_accuracy: 0.7522 - val_loss: 0.5432\n",
      "Epoch 9/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9588 - loss: 0.1356 - val_accuracy: 0.7638 - val_loss: 0.5118\n",
      "Epoch 10/10\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.9696 - loss: 0.1245 - val_accuracy: 0.7376 - val_loss: 0.5134\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 328ms/step - accuracy: 0.9182 - loss: 0.3142\n",
      "Average Test Accuracy: 0.7479399681091309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Example function for EEGNet model\n",
    "\n",
    "\n",
    "def EEGNet(nb_classes, Chans=21, Samples=500,\n",
    "           dropoutRate=0.25, kernLength=16, F1=64,\n",
    "           D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    input1 = Input(shape=(Chans, Samples, 1))\n",
    "\n",
    "    ##################################################################\n",
    "    block1 = Conv2D(F1, (1, 64), padding='same', use_bias=False)(input1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = DepthwiseConv2D((21, 1), use_bias=False,\n",
    "                             depth_multiplier=D)(block1)\n",
    "    block1 = BatchNormalization()(block1)\n",
    "    block1 = Activation('elu')(block1)\n",
    "    block1 = AveragePooling2D((1, 4))(block1)\n",
    "    block1 = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "    block2 = SeparableConv2D(\n",
    "        F2, (1, 16), padding='same', use_bias=True)(block1)\n",
    "    block2 = BatchNormalization()(block2)\n",
    "    block2 = Activation('elu')(block2)\n",
    "    block2 = AveragePooling2D((1, 8))(block2)\n",
    "    block2 = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "    flatten = Flatten(name='flatten')(block2)\n",
    "    dense = Dense(nb_classes, name='dense')(flatten)\n",
    "    softmax = Activation('softmax', name='softmax')(dense)\n",
    "\n",
    "    return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "\n",
    "# Define cross-validation strategy\n",
    "gkf = GroupKFold(n_splits=5)  # Example of 5-fold cross-validation\n",
    "\n",
    "\n",
    "accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    # Split data into train and test for this fold\n",
    "    train_data, test_data = data_array[train_index], data_array[test_index]\n",
    "    train_labels, test_labels = label_array[train_index], label_array[test_index]\n",
    "\n",
    "    # Split train data further into train and validation for this fold\n",
    "    train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "        train_data, train_labels, test_size=0.2)\n",
    "\n",
    "    # Preprocess data\n",
    "    scaler = StandardScaler()\n",
    "    train_features = scaler.fit_transform(\n",
    "        train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(\n",
    "        val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    test_features = scaler.transform(\n",
    "        test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\n",
    "\n",
    "    train_features = np.moveaxis(train_features, 1, 2)\n",
    "    val_features = np.moveaxis(val_features, 1, 2)\n",
    "    test_features = np.moveaxis(test_features, 1, 2)\n",
    "\n",
    "    train_features = np.reshape(train_features, (*train_features.shape, 1))\n",
    "    val_features = np.reshape(val_features, (*val_features.shape, 1))\n",
    "    test_features = np.reshape(test_features, (*test_features.shape, 1))\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    num_classes = 2  # Example number of classes\n",
    "    train_labels_onehot = np.zeros((train_labels.size, num_classes))\n",
    "    train_labels_onehot[np.arange(train_labels.size), train_labels] = 1\n",
    "\n",
    "    val_labels_onehot = np.zeros((val_labels.size, num_classes))\n",
    "    val_labels_onehot[np.arange(val_labels.size), val_labels] = 1\n",
    "\n",
    "    test_labels_onehot = np.zeros((test_labels.size, num_classes))\n",
    "    test_labels_onehot[np.arange(test_labels.size), test_labels] = 1\n",
    "\n",
    "    # Initialize model\n",
    "    model = EEGNet(num_classes, Chans=21, Samples=2500)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model on current fold's train and validation data\n",
    "    model.fit(train_features, train_labels_onehot, epochs=10,\n",
    "              batch_size=64, validation_data=(val_features, val_labels_onehot))\n",
    "\n",
    "    # Evaluate model on test data for this fold\n",
    "    test_loss, test_acc = model.evaluate(test_features, test_labels_onehot)\n",
    "    test_accuracy.append(test_acc)\n",
    "\n",
    "# After all folds, print average test accuracy\n",
    "print(\"Average Test Accuracy:\", np.mean(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8009478449821472,\n",
       " 0.7241379022598267,\n",
       " 0.7241379022598267,\n",
       " 0.75,\n",
       " 0.7404761910438538]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# # Example function for EEGNet model\n",
    "\n",
    "\n",
    "# def EEGNet(nb_classes, Chans=21, Samples=500,\n",
    "#            dropoutRate=0.25, kernLength=16, F1=64,\n",
    "#            D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):\n",
    "\n",
    "#     if dropoutType == 'SpatialDropout2D':\n",
    "#         dropoutType = SpatialDropout2D\n",
    "#     elif dropoutType == 'Dropout':\n",
    "#         dropoutType = Dropout\n",
    "#     else:\n",
    "#         raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "#                          'or Dropout, passed as a string.')\n",
    "\n",
    "#     input1 = Input(shape=(Chans, Samples, 1))\n",
    "\n",
    "#     ##################################################################\n",
    "#     block1 = Conv2D(F1, (1, 64), padding='same', use_bias=False)(input1)\n",
    "#     block1 = BatchNormalization()(block1)\n",
    "#     block1 = DepthwiseConv2D((21, 1), use_bias=False,\n",
    "#                              depth_multiplier=D)(block1)\n",
    "#     block1 = BatchNormalization()(block1)\n",
    "#     block1 = Activation('elu')(block1)\n",
    "#     block1 = AveragePooling2D((1, 4))(block1)\n",
    "#     block1 = dropoutType(dropoutRate)(block1)\n",
    "\n",
    "#     block2 = SeparableConv2D(\n",
    "#         F2, (1, 16), padding='same', use_bias=True)(block1)\n",
    "#     block2 = BatchNormalization()(block2)\n",
    "#     block2 = Activation('elu')(block2)\n",
    "#     block2 = AveragePooling2D((1, 8))(block2)\n",
    "#     block2 = dropoutType(dropoutRate)(block2)\n",
    "\n",
    "#     flatten = Flatten(name='flatten')(block2)\n",
    "#     dense = Dense(nb_classes, name='dense')(flatten)\n",
    "#     softmax = Activation('softmax', name='softmax')(dense)\n",
    "\n",
    "#     return Model(inputs=input1, outputs=softmax)\n",
    "\n",
    "# # Define cross-validation strategy\n",
    "\n",
    "\n",
    "# gkf = GroupKFold(n_splits=5)  # Example of 5-fold cross-validation\n",
    "\n",
    "# accuracy = []\n",
    "# test_accuracy = []\n",
    "\n",
    "# # Loop over each fold\n",
    "# for train_index, test_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "#     # Split data into train and test for this fold\n",
    "#     train_data, test_data = data_array[train_index], data_array[test_index]\n",
    "#     train_labels, test_labels = label_array[train_index], label_array[test_index]\n",
    "\n",
    "#     # Split train data further into train and validation for this fold\n",
    "#     train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "#         train_data, train_labels, test_size=0.2)\n",
    "\n",
    "#     # Preprocess data\n",
    "#     scaler = StandardScaler()\n",
    "#     train_features = scaler.fit_transform(\n",
    "#         train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "#     val_features = scaler.transform(\n",
    "#         val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "#     test_features = scaler.transform(\n",
    "#         test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\n",
    "\n",
    "#     train_features = np.moveaxis(train_features, 1, 2)\n",
    "#     val_features = np.moveaxis(val_features, 1, 2)\n",
    "#     test_features = np.moveaxis(test_features, 1, 2)\n",
    "\n",
    "#     train_features = np.reshape(train_features, (*train_features.shape, 1))\n",
    "#     val_features = np.reshape(val_features, (*val_features.shape, 1))\n",
    "#     test_features = np.reshape(test_features, (*test_features.shape, 1))\n",
    "\n",
    "#     # Convert labels to one-hot encoding\n",
    "#     num_classes = 2  # Example number of classes\n",
    "#     train_labels_onehot = np.zeros((train_labels.size, num_classes))\n",
    "#     train_labels_onehot[np.arange(train_labels.size), train_labels] = 1\n",
    "\n",
    "#     val_labels_onehot = np.zeros((val_labels.size, num_classes))\n",
    "#     val_labels_onehot[np.arange(val_labels.size), val_labels] = 1\n",
    "\n",
    "#     test_labels_onehot = np.zeros((test_labels.size, num_classes))\n",
    "#     test_labels_onehot[np.arange(test_labels.size), test_labels] = 1\n",
    "\n",
    "#     # Initialize model\n",
    "#     model = EEGNet(num_classes, Chans=21, Samples=2500)\n",
    "\n",
    "#     # Compile model\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='binary_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     # Train model on current fold's train and validation data\n",
    "#     model.fit(train_features, train_labels_onehot, epochs=10,\n",
    "#               batch_size=64, validation_data=(val_features, val_labels_onehot))\n",
    "\n",
    "#     # Evaluate model on test data for this fold\n",
    "#     test_loss, test_acc = model.evaluate(test_features, test_labels_onehot)\n",
    "#     test_accuracy.append(test_acc)\n",
    "\n",
    "#     # After all folds, print average test accuracy\n",
    "#     print(\"Average Test Accuracy:\", np.mean(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
